<!DOCTYPE html>
<html lang="en">

  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NX2X9J1TMG"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NX2X9J1TMG');
    </script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Vinitra Swamy</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">

    <link rel="shortcut icon" href="old/images/favicon.ico" type="image/x-icon">
    <link rel="icon" href="old/images/favicon.ico" type="image/x-icon">

  </head>

  <body id="page-top">
    <!-- Cloudflare Web Analytics --><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "f11ea8f1d58847c8918fdc30f1d2cba7"}'></script><!-- End Cloudflare Web Analytics -->

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Vinitra Swamy</span>
        <span class="d-none d-lg-block">
          <span class="d-none d-lg-block"><b>V I N I T R A</b></span>
          <br>
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/vini.jpeg" alt="">
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#research">Research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#experience">Industry</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#education">Education</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#speaking">Teaching</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
          </li>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">Vinitra
            <span class="text-primary">Swamy</span>
          </h1>
          <div class="subheading mb-5"> PhD Candidate at EPFL · Deep Learning Research ·
            <a href="mailto:vinitra@berkeley.edu"> vinitra@berkeley.edu</a> <br>

          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              
              <p>Hello! I am an AI researcher and PhD student working on deep learning model explainability at <a href="https://www.epfl.ch/">École Polytechnique Fédérale de Lausanne (EPFL)</a>. I'm coadvised by Prof. Tanja Käser at the <a href="https://www.epfl.ch/labs/d-vet/">ML4Ed Lab</a> and Prof. Martin Jaggi at the <a href="https://www.epfl.ch/labs/mlo/">MLO Lab</a>.</p>

              <p>Before moving to Switzerland, I worked for two years at <img class="mx-auto mb-1" src="img/msft.png" alt="" width="18"> Microsoft AI as a lead engineer for the <a href="http://onnx.ai">Open Neural Network eXchange project</a>.</p>

              <p>My claim to fame (haha) is that I graduated at 20 as the youngest M.S. in Computer Science recipient in UC Berkeley's history.  Since then, I've served as a machine learning lecturer for the <a href="https://classes.berkeley.edu/content/2018-summer-stat-c8-001-lec-001"> <img class="mx-auto mb-1" src="img/berkeley.png" alt="" width="21"> Berkeley Division of Data Sciences</a> 
                and the <a href="https://courses.cs.washington.edu/courses/cse416/20su/overview.html"><img class="mx-auto mb-1" src="img/uw.png" alt="" width="21"> University of Washington CSE Department</a>.</p>

               <p>I love people, data, and working on exciting problems at the intersection of the two: </p>

               <ul class="fa-ul mb-0">
                <li>
                 <i class="fa-li fa fa-check"></i>
                  explainable and interpretable AI</li>
                <li>
                  <i class="fa-li fa fa-check"></i>
                  generalized learning (transfer learning, meta learning)</li>
                <li>
                  <i class="fa-li fa fa-check"></i>
                  ML for education (autograding, knowledge tracing, scalable infrastructure)</li>
              </ul><br>

              <p> Thank you for taking time out of your day to find out what I do with mine!</p>

          <ul class="list-inline list-social-icons mb-0">
            <li class="list-inline-item">
              <a href="http://linkedin.com/in/vinitra">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="http://github.com/vinitra">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://scholar.google.com/citations?hl=en&user=SX9GAqwAAAAJ">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-graduation-cap fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="http://twitter.com/vinitra_s">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
            </div>
            <div class="resume-date text-md-right">
            </div>
          </div>


        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="research">
        <div class="my-auto">
          <h2 class="mb-5">Selected Research</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">

              <h3 class="mb-0">MultiModN (NeurIPS 2023)</h3>
              <div class="subheading mb-3">Vinitra Swamy*, Malika Satayeva*, Jibril Frej, Thierry Bossy, Thijs Vogels, Martin Jaggi, Tanja Käser*, Mary-Anne Hartley*</div>            
              
              <p> We present MultiModN, a multimodal, modular network that fuses latent representations in a sequence of any number, combination, or type of modality while providing granular real-time predictive feedback on any number or combination of predictive tasks. <b>MultiModN's composable pipeline is interpretable-by-design, as well as innately multi-task and robust to the fundamental issue of biased missingness.</b> We perform four experiments on several benchmark MM datasets across 10 real-world tasks (predicting medical diagnoses, academic performance, and weather), and show that MultiModN's sequential MM fusion does not compromise performance compared with a baseline of parallel fusion.</p>
              [<a href="https://arxiv.org/abs/2309.14118">Pre-Print</a>] [<a href="https://github.com/epfl-iglobalhealth/multimodn">Code</a>]</p>


              </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">2023</span>
              </div> 
              </div>  

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">

              <h3 class="mb-0">Unraveling Downstream Bias from LLMs (EMNLP Findings 2023)</h3>
              <div class="subheading mb-3">Thiemo Wambsganss*, Xiaotian Su*, Vinitra Swamy, Parsa Seyed Neshai, Roman Rietsche, Tanja Käser</div>            
              
              <p> We investigate how bias transfers through an AI writing support pipeline through a large scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support (traditional ML suggestions, control group with no assistance, finetuned versions of GPT2, GPT 3, and GPT3.5). Using GenBit, WEAT, and SEAT, we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore <b>optimistic about the use of AI writing support in the classroom</b>, showcasing a context where <b>bias in LLMs does not transfer to students' responses</b>.</p>
              [<a href="https://arxiv.org/abs/2311.03311">Pre-Print</a>] [<a href="https://github.com/epfl-ml4ed/unraveling-llm-bias">Code</a>]</p>


              </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">2023</span>
              </div> 
              </div>  

            <div class="resume-item d-flex flex-column flex-md-row mb-5">
              <div class="resume-content mr-auto">
  
                <h3 class="mb-0">Viewpoint: Future of Human-Centric XAI (Submitted to JAIR)</h3>
                <div class="subheading mb-3">Vinitra Swamy, Jibril Frej, Tanja Käser</div>            
                
                <p> Current approaches in human-centric XAI (e.g. predictive tasks in healthcare, education, or personalized ads) tend to rely on a single explainer. This is a concerning trend given systematic disagreement in explainability methods applied to the same points and underlying black-box models. We propose to shift from post-hoc explainability to designing interpretable neural network architectures; moving away from approximation techniques in human-centric and high impact applications. We <b>identify five needs of human-centric XAI (real-time, accurate, actionable, human-interpretable, and consistent) and propose two schemes for interpretable-by-design neural network workflows</b> (adaptive routing for interpretable conditional computation and diagnostic benchmarks for iterative model learning). We postulate that the future of human-centric XAI is neither in explaining black-boxes nor in reverting to traditional, interpretable models, but in neural networks that are intrinsically interpretable.
                </p>
                [<a href="https://arxiv.org/abs/2307.00364">Pre-Print</a>]</p>
                
  
                </div>
                <div class="resume-date text-md-right">
                  <span class="text-primary">2023</span>
                </div> 
                </div>  

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Trusting the Explainers (LAK 2023, Honorable Mention)</h3>
              <div class="subheading mb-3">Vinitra Swamy, Sijia Du, Mirko Marras, and Tanja Käser</div>
              
              <p> We use human experts to validate explainable AI approaches in the context of student success prediction. Our pairwise analyses cover five course pairs (nine datasets from Coursera, EdX, and Courseware) that differ in one educationally relevant aspect and popular instance-based explainers. We quantitatively compare the distances between the explanations across courses and methods, then validate the explanations of LIME, SHAP, and a counterfactual-based confounder with 26 semi-structured interviews of university-level educators regarding which features they believe contribute most to student success, which explanations they trust most, and how they could transform these insights into actionable course design decisions. <b>Our results show that quantitatively, explainers significantly disagree with each other about what is important, and qualitatively, experts themselves do not agree on which explanations are most trustworthy.</b></p>
              [<a href="https://dl.acm.org/doi/10.1145/3576050.3576147">Paper</a>] [<a href="https://arxiv.org/abs/2212.08955">Pre-Print</a>] [<a href="https://github.com/epfl-ml4ed/trusting-explainers">Code</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2023</span>
            </div>
            </div>



          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Ripple: Concept-Based Interpretation for Raw Time Series (AAAI 2023)
              </h3>
              <div class="subheading mb-3">Mohammad Asadi (intern), Vinitra Swamy, Jibril Frej, Julien Vignoud, Mirko Marras, Tanja Käser</div>
              <p> We present RIPPLE, utilizing irregular multivariate time series modeling with graph neural networks to achieve comparable or better accuracy with raw time series clickstreams in comparison to hand-crafted features. Furthermore, we extend concept activation vectors for interpretability in raw time series models. Our experimental analysis on 23 MOOCs with millions of combined interactions over six behavioral dimensions show that <b>models designed with our approach can (i) beat state-of-the-art time series baselines with no feature extraction and (ii) provide interpretable insights for personalized interventions</b>.
              </p>
               [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/26888">Paper</a>] [<a href="https://arxiv.org/abs/2212.01133">Pre-Print</a>] [<a href="files/PDF_AAAI2023_Vinitra.pdf">Slides</a>] [<a href="https://github.com/epfl-ml4ed/ripple/">Code</a>]</p>
            </div>

            <div class="resume-date text-md-right">
              <span class="text-primary">2023</span>
            </div>

          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">

              <h3 class="mb-0">Evaluating the Explainers (EDM 2022)</h3>
              <div class="subheading mb-3">Vinitra Swamy, Bahar Radhmehr, Natasa Krco, Mirko Marras, and Tanja Käser</div>            
              
              <p> We compare five explainers for black-box neural nets (LIME, PermutationSHAP, KernelSHAP, DiCE, CEM) on the downstream task of student performance prediction for five massive open online courses. Our experiments demonstrate that the families of explainers <b>do not agree</b> with each other on feature importance for the same Bidirectional LSTM models with the same representative set of students. We use Principal Component Analysis, Jensen-Shannon distance, and Spearman's rank-order correlation to quantitatively cross-examine explanations across methods and courses. <b>Our results come to the concerning conclusion that the choice of explainer contains systematic bias and is in fact paramount to the interpretation of the predictive results, even more so than the data the model is trained on.</b></p>
              [<a href="https://educationaldatamining.org/edm2022/proceedings/2022.EDM-long-papers.9/2022.EDM-long-papers.9.pdf">Paper</a>] [<a href="https://arxiv.org/abs/2207.00551">Pre-Print</a>] [<a href="files/PDF_EDM2022_Vinitra.pdf">Slides</a>] [<a href="https://github.com/epfl-ml4ed/evaluating-explainers">Code</a>]</p>
              

              </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">2022</span>
              </div> 
              </div>       
          
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Meta Transfer Learning (ACM L@S 2022)</h3>
              <div class="subheading mb-3">Vinitra Swamy, Mirko Marras, and Tanja Käser</div>
              <p> We tackle the problem of transferability across MOOCs from different domains and topics, focusing on models for early success prediction. In this paper, we present and analyze three novel strategies to creating generalizable models: 1) pre-training a model on a large set of diverse courses, 2) leveraging the pre-trained model by including meta features about courses to orient downstream tasks, and 3) fine-tuning the meta transfer learning model on previous course iterations. Our experiments on 26 MOOCs with over 145,000 combined enrollments and millions of interactions show that <b>models combining interaction clickstreams and meta information have comparable or better performance than models which have access to previous iterations of the course</b>. With these models, we enable educators to <b>warm-start their predictions</b> for new and ongoing courses.</p>
              [<a href="https://dl.acm.org/doi/10.1145/3491140.3528273">Paper</a>] [<a href="https://arxiv.org/abs/2205.01064">Pre-Print</a>] [<a href="files/PDF_L@S2022_Vinitra.pdf">Slides</a>] [<a href="https://github.com/epfl-ml4ed/meta-transfer-learning">Code</a>] </p>
            </div>

            <div class="resume-date text-md-right">
              <span class="text-primary">2022</span>
            </div>

          </div>


          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Interpreting LMs Through KG Extraction (NeurIPS 2021)</h3>
              <div class="subheading mb-3">Vinitra Swamy, Angelika Romanou, and Martin Jaggi</div>
              <p> While transformer-based language models are undeniably useful, it is a challenge to quantify their performance beyond traditional accuracy metrics. In this paper, we compare BERT-based language models (DistilBERT, BERT, RoBERTa) through snapshots of acquired knowledge at sequential stages of the training process. We contribute a quantitative framework to compare language models through knowledge graph extraction and showcase a part-of-speech analysis to identify the linguistic strengths of each model variant. Using these metrics, machine learning practitioners can <b>compare models, diagnose their models' behavioral strengths and weaknesses, and identify new targeted datasets to improve model performance</b>.</p>
              <p> Published at eXplainable AI for Debugging and Diagnosis Workshop at <a href="https://xai4debugging.github.io/">NeurIPS 2021</a>. </p>
              [<a href="https://xai4debugging.github.io/files/papers/interpreting_language_models_t.pdf">Paper</a>] [<a href="files/Poster_NeurIPS2021_InterpretingLanguageModels.pdf">Poster</a>] [<a href="https://github.com/epfml/interpret-lm-knowledge">Code</a>]</p>
            </div>

            <div class="resume-date text-md-right">
              <span class="text-primary">2021</span>
            </div>

          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">ONNX: Open Neural Network eXchange</h3>
              <p> Open Neural Network Exchange (<a href="http://onnx.ai">ONNX</a>) is an open standard for machine learning interoperability. Founded by Microsoft and Facebook, and now supported by over 30 other companies, ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers. </p>
              [<a href="https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/deployment/onnx">ONNX + Azure ML Tutorials</a>]</p>

              <div class="subheading mb-3">Microsoft MLADS Conference (Machine Learning, AI, and Data Science)</div>
              <p> Gave a talk to data scientists and engineers at MLADS Spring 2019 on model operationalization and acceleration with ONNX alongside Emma Ning, Spandan Tiwari, Nathan Yan, and Lara Haidar-Ahmad.</p>
              <p>[<a href="https://notebooks.azure.com/qining/projects/285-lab-session-in-mlads-2019">Notebooks</a>]  [<a href="https://www.dropbox.com/s/d7zqosvjvytu8yx/285%20Lab%2C%20Ning.pdf?dl=0">Slides</a>]</p>

              <div class="subheading mb-3">University of Washington eScience Institute</div>
              <p> Overview of AI model interoperability with ONNX and ONNX Runtime for data scientists and researchers at University of Washington, Seattle.</p>
              <p>[<a href="https://www.dropbox.com/s/3sx7jhmcx6p1xq5/ONNX_UW_lightning%20talk.pptx?dl=0">Slides</a>]</p>
            </div>

            <div class="resume-date text-md-right">
              <span class="text-primary">2020</span>
            </div>

          

          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">ML for Humanitarian Data: Tag Prediction using the HXL Standard (KDD 2019)</h3>
              <div class="subheading mb-3"> Vinitra Swamy (Microsoft AI), Elisa Chen, Anish Vankayalapati, Abhay Aggarwal, Chloe Liu (UC Berkeley), Vani Mandava (MSR), Simon Johnson (UN)</div>
              <p> We present a simple yet effective machine learning model to predict tags for datasets from the United Nations Office for the Coordination of Humanitarian Affairs (<a href="https://www.unocha.org/">UN OCHA</a>) with the labels and attributes of the Humanitarian Exchange Language (<a href="http://hxlstandard.org/">HXL</a>) Standard for data interoperability. This paper details the methodology used to predict the corresponding tags and attributes for a given dataset with an accuracy of 94% for HXL header tags and an accuracy of 92% for descriptive attributes. Compared to previous work, our workflow provides a 14% accuracy increase and is a novel case study of using ML to enhance humanitarian data. </p>
              <p>[<a href="https://www.kdd.org/kdd2019/docs/Humanitarian_Data_tagging_KDD2019_SocialImpactTrack_HXLTagPrediction.pdf">Paper</a>] [<a href="https://www.dropbox.com/s/17vlx8gw01zil3u/Vinitra-KDD-HumDataPresentation.pptx?dl=0">Slides</a>]  [<a href="https://www.dropbox.com/s/1263fkgoe6x6vee/poster-hxl.pdf?dl=0">Poster</a>] [<a href="https://github.com/humanitarian-data-collaboration">Code</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2019</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Pedagogy, Infrastructure, and Analytics for Data Science Education at Scale</h3>
              <div class="subheading mb-3"> (Master's Thesis) Vinitra Swamy, David Culler</div>

              <p> A detailed research report on autograding, analytics, and scaling JupyterHub infrastructure highlighted in use for thousands of students taking <a href="http://data8.org">Data 8</a> at UC Berkeley. Presented as a graduate student affiliated with <a href="https://rise.cs.berkeley.edu/blog/author/vinitra/">RISELab</a>.</p>
              <p>[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-81.html">Thesis</a>] </p>
              <br>
              <div class="subheading mb-3">Deep Knowledge Tracing for Student Code Progression (AIED 2018)</div>
              <p>Vinitra Swamy, Samuel Lau, Allen Guo, Madeline Wu, Wilton Wu, Zachary Pardos, David Culler. Paper published at published at <a href="https://aied2018.utscic.edu.au/">Artificial Intelligence in Education</a> / International Festival of Learning 2018 in London, England.</p>
              <p>Knowledge Tracing is a body of learning science literature that seeks to model student knowledge acquisition through their interaction with coursework. This project uses a recurrent neural network (LSTM) and free-form code attempts to model student knowledge in large scale computer science classes.</p>
              
              <p>[<a href="https://link.springer.com/chapter/10.1007%2F978-3-319-93846-2_65">Paper</a>] [<a href="https://www.dropbox.com/s/pel677yohdqobwy/AIED_DKTCodeProgression_Poster%20%288%29.pdf?dl=0">Poster</a>]</p>
              <br>
              <div class="subheading mb-3">Project Jupyter: Scaling JupyterHub for Data Science Education (JupyterCon 2017)</div>
              <p>Helped develop UC Berkeley data science's software infrastructure stack including JupyterHub, autograding with OkPy, Gradescope, and authentication for 1000s of students.</p>
              <p>[<a href="https://blog.jupyter.org/introducing-the-helm-chart-for-jupyterhub-deployment-with-kubernetes-b79bfd18566d">Blog</a>] [<a href="https://github.com/data-8">Code</a>] </p>
              <br>
              <p>Collaborated with Yuvi Panda, Ryan Lovett, Chris Holdgraf, and Gunjan Baid on a talk detailing the infrastructure stack at JupyterCon 2017.</p>
              <p>[<a href="https://cdn.oreillystatic.com/en/assets/1/event/271/Data%20science%20at%20UC%20Berkeley_%202%2C000%20undergraduates%2C%2050%20majors%2C%20no%20command%20line%20Presentation.pdf">Slides</a>] [<a href="https://conferences.oreilly.com/jupyter/jup-ny-2017/public/schedule/speaker/279664">Speaker Profile</a>] </p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2018</span>
            </div>
          </div>
          
          <!-- </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">CSi2: Idle Server Identification</h3>
              <div class="subheading mb-3">IBM Research, T.J Watson Research Center</div>
              <p>Recent studies have shown that "zombie" virtual machines in hybrid/private clouds have been wasting millions of dollars worth of resources. The CSi2 algorithm is an ensemble machine learning algorithm to detect inactivity of VMs as well as suggest a course of action like termination or snapshot. It is projected to save IBM Research at least $3.2 million dollars with 95.12% recall and 88% F1 score (>> industry standard) and is being implemented into the Watson Services Platform. 2 patents have been filed.</p>
              <p>Collaborated with Neeraj Asthana, Sai Zheng, Ivan D'ell Era, Aman Chanana.</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Neural Style Transfer for Non-Parallel Text</h3>
              <div class="subheading mb-3">Natural Language Processing</div>
              <p>Expanded on an MIT CSAIL paper by Shen et. al. to improve the accuracy of neural style transfer for unaligned text using author disambiguation algorithms. </p>
              <p>Collaborated with Vasilis Oikonomou and Professor David Bamman.</p>
              <p>[<a href="https://github.com/vinitra/neural-text-style-transfer">Code</a>]</p>
              <br>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Blog Post: Deep Sentiment Analysis</h3>
              <div class="subheading mb-3">Natural Language Processing</div>
              <p>A Distill-style (interactive visualization) introduction and literature review of neural networks for Natural Language Processing, specifically in the field of analyzing sentiment and emotion.</p>
              <p>Collaborated with Stefan Palombo and Michael Brenndoerfer.</p>
              <p>[<a href="https://brenndoerfer.github.io/deep-sentiment-analysis-distill/index.html">Blog</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017</span>
            </div>
          </div> -->

          <!-- <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Deep Causal Reward Design</h3>
              <div class="subheading mb-3">Fairness in Machine Learning</div>
              <p>Exploring reward design for reinforcement learning through the framework of causality and fairness. Class project later expanded into a short paper at CausalML workshop at NeurIPS 2018 by collaborators.</p>
              <p>[<a href="https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxmYWltMTh3c2NhdXNhbG1sfGd4OjYxMGIzYjJiNzA3MzdkNA">Paper</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017</span>
            </div>
          </div> -->

          <!-- <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Other Research Projects</h3>
              <div class="subheading mb-3">Deep DJ: Musical Score Generation for Video</div>
              <p>Extracting sentiment from video frames, experimenting with GANs for audio, and ultimately using a neural style transfer for audio technique to generate unique musical tracks for video.</p>
              <p>[<a href="https://medium.com/@kaylee.c.burns/deep-dj-musical-score-generation-for-video-870959e4e263">Blog</a>] [<a href="https://github.com/vinitra/music-score-gen">Code</a>]</p>
              <div class="subheading mb-3">Goodly Labs: Deciding Force</div>
              <p>Advising on data science project to extract key information surrounding police activity from news articles.</p>
              <p>[<a href="https://bids.berkeley.edu/research/deciding-force">Project Overview</a>] [<a href="https://goodlylabs.org/">Website</a>]</p>
              <div class="subheading mb-3">BIDS: Ecosystem Mapping Initiative</div>
              <p>ETL pipeline and web scraper to determine graph of collaborations between professors and researchers across institutions.</p>
              <p>[<a href="https://github.com/BIDS-projects">Code</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2018</span>
            </div>
          </div>

        </div> -->

      </section>


      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="experience">
        <div class="my-auto">


          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Microsoft AI</h3>
              <div class="subheading mb-3">AI Software Engineer</div>
              <p>Working on a framework for deep learning / ML framework interoperability (<a href="http://onnx.ai">ONNX</a>) alongside an ecosystem of converters, containers, and inference engines.</p>
              <p>Lead of the inter-company ONNX Special Interest Group (SIG) for <a href="https://github.com/onnx/models">Model Zoo and Tutorials</a> with Microsoft, Intel, Facebook, IBM, nVidia, RedHat, and other academic and industry collaborators. </p>
              <p>Presented and represented Microsoft AI at several conferences: WIDS 2020, Microsoft //Build 2019, KDD 2019, Microsoft Research Faculty Summit 2019, UC Berkeley AI for Social Impact Conference 2018, Women in Cloud Summit 2018, RISECamp 2018 </p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2018 - 2020</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Berkeley Insitute for Data Science (BIDS), RISELab</h3>
              <div class="subheading mb-3">Research Assistant</div>
              <p>Worked on projects in AI + Systems with an application area of data science education. Project areas include JupyterHub architecture, custom deployments, OkPy autograding integration, Jupyter noteboook extensions, and D3.js / PlotLy visualizations for data science explorations of funding and enrollment data.</p>
              <p>[<a href="http://bids.berkeley.edu">BIDS</a>] [<a href="https://rise.cs.berkeley.edu/blog/author/vinitra/">RISELab</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2015 - 2018</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">IBM Research</h3>
              <div class="subheading mb-3">Research Scientist Intern, Machine Learning</div>
              <p>Worked on the CSi2 project as a Machine Learning Research Scientist intern on the Hybrid Cloud team. The CSi2 algorithm is an ensemble machine learning algorithm to detect inactivity of VMs as well as suggest a course of action (i.e. termination, snapshot). It is projected to save IBM Research at least $3.2 million dollars with 95.12% recall and 88% F1 score (>> industry standard) and is being implemented into the Watson Services Platform. Collaborated with Neeraj Asthana, Sai Zheng, Ivan D'ell Era, Aman Chanana. Presented an exit talk and filed 2 patents.</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">LinkedIn</h3>
              <div class="subheading mb-3">Software Engineering Intern</div>
              <p>Interned at LinkedIn headquarters with the Growth Division's Search Engine Optimization (SEO) Team the summer before entering UC Berkeley. Worked on fullstack testing infrastructure for the public profile pages, as well as a Hadoop project; outside of assigned work, helped plan LinkedIn’s DevelopHER Hackathon and worked on several Market Research/User Experience Design initiatives.</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2015</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Google </h3>
              <div class="subheading mb-3">Intern, Made w/ Code Ambassador</div>
              <p>Spent a summer learning computer science fundamentals and shadowing engineers through the CAPE high school internship program at Google Headquarters in Mountain View, CA. Chosen as a Google Ambassador for Computer Science following the experience. Worked with Google, Salesforce, and AT&amp;T to introduce coding to over 15,000 girls across California with the <a href="https://www.madewithcode.com">Made w/ Code</a> Initiative.
              </p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2011</span>
            </div>
          </div>
        </div>

      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="education">
        <div class="my-auto">
          <h2 class="mb-5">Education</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">École Polytechnique Fédérale de Lausanne</h3>
              <div class="subheading mb-3">PhD in Computer Science</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                President of EPFL PhDs in Computer Science (<a href="https://www.epfl.ch/campus/associations/list/epic/">EPIC</a>)</li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                Advised by Prof. Tanja Käser at the <a href="https://www.epfl.ch/labs/ml4ed/">ML4ED Lab</a> <br>
                and Prof. Martin Jaggi at the <a href="https://www.epfl.ch/labs/mlo/page-135382-en-html/">MLO Lab</a></li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                EDIC Computer Science Fellowship Recipient, EPFL IC Distinguished Service Award</li>
              </ul>

             </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2020 - Current</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">University of California, Berkeley</h3>
              <div class="subheading mb-3">Master's in Electrical Engineering and Computer Science</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                President of Computer Science Honor Society (<a href="http://upe.berkeley.edu">UPE</a>)</li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                Head Graduate Student Instructor of Data 8 (<a href="http://data8.org">Foundations of Data Science</a>)</li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                Research Assistant, Graduate Opportunity Fellow at <a href="https://rise.cs.berkeley.edu/blog/author/vinitra/">RISELab</a></li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                <b>Advisor</b>: Dean of Data Sciences, David Culler</li>
              </ul>

             </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2017 - 2018</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">University of California, Berkeley</h3>
              <div class="subheading mb-3">Bachelor's in Computer Science</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                EECS Award of Excellence in Undergraduate Teaching and Leadership</li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                UC Berkeley Alumni Leadership Scholar</li>
              <li>
                <i class="fa-li fa fa-graduation-cap text-warning"></i>
                Graduated 2 years early</li>
              </ul>
             </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2015 - 2017</span>
            </div>
          </div>

        </div>
      </section>

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="speaking">
        <div class="my-auto">
          <h2 class="mb-5">Teaching Experience </h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Machine Learning, Data Analysis, Databases</h3>
              <div class="subheading mb-3">EPFL</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                <b>Spring 2022, 2023</b>: TA for <a href="https://edu.epfl.ch/coursebook/en/applied-data-analysis-CS-401">CS 421 - Machine Learning for Behavioral Data</a> with Tanja Käser</li>
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                <b>Fall 2021</b>: TA for <a href="https://edu.epfl.ch/coursebook/en/applied-data-analysis-CS-401">CS 401 - Applied Data Analysis</a> with Bob West</li>
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                <b>Spring 2021</b>: TA for <a href="https://edu.epfl.ch/coursebook/en/introduction-to-database-systems-CS-322">CS 322 - Introduction to Database Systems</a> with Anastasia Alaimaki and Christoph Koch</li>
              </ul>
              <br>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2020 - 2024</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">CSE/STAT 416: Introduction to Machine Learning</h3>
              <div class="subheading mb-3">University of Washington, Seattle</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                <b>Lecturer</b> to 100+ upper-division undergraduate and graduate students on a practical introduction to machine learning. Modules include regression, classification, clustering, retrieval, recommender systems, and deep learning, with a focus on an intuitive understanding grounded in real-world applications.</li>
              </ul>
              <br>
              <p>[<a href="https://courses.cs.washington.edu/courses/cse416/20su/">CSE 416 Website</a>] </p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">Summer 2020</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Data 8: Foundations of Data Science</h3>
              <div class="subheading mb-3">UC Berkeley</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                <b>Lecturer</b> to 250+ undergraduate students on fundamentals of statistical inference, computer programming, and inferential thinking.</li>
              </ul>
              <br>
              <p>[<a href="http://data8.org/su18/">Data 8 Website</a>] [<a href="https://classes.berkeley.edu/content/2018-summer-stat-c8-001-lec-001">Course Offering</a>] [<a href="https://github.com/data-8/materials-su18">Course Materials / Code</a>]</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">Summer 2018</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Data 8: Foundations of Data Science</h3>
              <div class="subheading mb-3">UC Berkeley</div>
              <ul class="fa-ul mb-0">
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                TA / Head Graduate Student Instructor (GSI) of Data 8 for 4 semesters, responsible for management of 1000+ undergraduates, 40 GSIs, 30 tutors, and 100+ lab assistants each semester.</li>
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                Helped create data science curriculum material for lecture and domain-specific seminar courses.</li>
              <li>
                <i class="fa-li fa fa-book text-warning"></i>
                In charge of developing JupyterHub infrastructure for 1500+ active users (with Jupyter Servers with Docker/Kubernetes backend on top of various cloud providers including Google Cloud, Azure, and AWS).</li>
              </ul>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">2016 - 2018</span>
            </div>
          </div>

      <div class="resume-item d-flex flex-column flex-md-row mb-5">
        <div class="resume-content mr-auto">
          <h3 class="mb-0">Organizing Team</h3>
          <p><a href="https://wimlworkshop.org/">WiML Program Chair </a> @ ICML 2022 <br>
          <a href="http://fated2022.github.io">FATED Workshop Co-Chair</a> @ <a href="files/2022.EDM-workshop-tutorials.114.pdf">EDM 2022</a></p>

          <h3 class="mb-0">Reviewer / Program Committee </h3>
          <p>AIED Program Committee 2023
            <br> AIED 2021*, 2022* (Subreviewer for Tanja Käser)
            <br> EMNLP BlackBoxNLP 2021, 2022, 2023
            <br> EACL 2022
            <br> EDM 2023
            <br> Journal of Educational Data Mining (JEDM) 2022 
            <br> LAK 2022*, 2023* (Subreviewer for Tanja Käser)
            <br> Editor for Springer Series on Big Data Management (Educational Data Science) </p>

          <h3 class="mb-0">Working Groups</h3>
          <p>Fairness Working Group @ EDM 2022 <br> WiML Workshop Team @ NeurIPS 2021 <br> Lead of the 2020 ONNX SIG for Models and Tutorials </p>
        </div>

        <div class="resume-date text-md-right">
          <span class="text-primary">2023</span>
        </div>

      </div>

    </section>


      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="awards">
        <div class="my-auto">
          <h2 class="mb-5">Awards</h2>
            <ul class="fa-ul mb-0">
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
                EPFL IC Distinguished Service Award 2021, 2022</li>
            <li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
                EPFL Computer Science (EDIC) Fellowship</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
                UC Berkeley EECS Award of Excellence for Teaching and Leadership</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              Google International Trailblazer in Computer Science</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              UC Berkeley Graduate Opportunity Fellowship</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              Kairos Society Entrepreneurship Fellow, UC Berkeley</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              President of <a href="http://upe.berkeley.edu">UPE</a>, UC Berkeley Computer Science Honor Society</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              UC Berkeley Alumni Leadership Scholar</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              NASA-Conrad Foundation Spirit of Innovation Cybertechnology Finalist</li>
            <li>
              <i class="fa-li fa fa-trophy text-warning"></i>
              Girl Scout Gold Award: Bridging the Digital Divide</li>
          </ul>

          <br>

          <h3 class="mb-0">Speaking Engagements</h3>
          <ul class="fa-ul mb-0">
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2022</b>: Speaker at Oxford ML "Un-Workshop" Series on Evaluating Explainable AI</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2022</b>: Opening Remarks at the <a href="files/2022.EDM-workshop-tutorials.114.pdf">FATED workshop</a> at EDM 2022 (Durham, UK)</li> 
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2022</b>: Speaker at Women in Data Science <a href="https://events.sap.com/sap-purpose-network-live/en/wids-at-sap-2022">(WIDS 2022)</a> Silicon Valley: Explainable AI</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2021</b>: Spotlight Talk at NeurIPS Inaugural eXplainable AI for Debugging and Diagnosis Workshop</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2021</b>: Presenter at the Tamil Internet Conference (INFITT) on "TamilBERT: Natural Language Modeling for Tamil"</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2021</b>: Presenter at the EDIC Orientation for PhDs, EPFL</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2021</b>: UC Berkeley Data Science Alumni Panel </li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2020</b>: Featured Guest on the Tech Gals Podcast (<a href="https://www.techgalspod.com/episodes/ep3">Episode 3</a>) </li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2020</b>: Speaker at the <a href="https://events.linuxfoundation.org/lf-ai-day-onnx-community-virtual-meetup-fall/program/schedule/">ONNX Workshop</a></li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2020</b>: Speaker at Women in Data Science Conference <a href="https://events.sap.com/us/wids-2020-sv/">(WIDS 2020)</a> Silicon Valley: Interoperable AI (ONNX)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2020</b>: Speaker at the <a href="https://events.linuxfoundation.org/lf-ai-day-onnx-community-virtual-meetup/program/schedule/">Linux Foundation (LF) AI Day</a></li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2019</b>: Presenter at <a href="https://www.youtube.com/watch?v=-Ctp1HgP3WU">Microsoft Bay Area AI Meetup</a> </li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2019</b>: Guest on the <a href="https://www.youtube.com/watch?v=pmb6cjngbcA">Microsoft AI Show</a> (Channel 9)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2019</b>: Speaker at Microsoft Machine Learning and Data Science Conference (MLADS) (Redmond)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2018</b>: Presenter at Artificial Intelligence in Education 2018 (London)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2018</b>: Speaker at UC Berkeley's Data Science Undergraduate Pedagogy and Practice Workshop (Berkeley)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2017</b>: Opening Panelist at SalesForce Dreamforce Conference (SF)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2017</b>: Speaker at JupyterCon (NYC)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Spring 2017</b>: Presenter at Berkeley Institute for Data Science Research Showcase (Berkeley)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Fall 2016</b>: Panelist at SF BusinessWeek Conference (SF)</li>
            <li>
              <i class="fa-li fa fa-microphone text-warning"></i>
              <b>Summer 2016</b>: Conference organizing team at Algorithms for Modern Massive Data Sets (<a href="http://mmds-data.org/">MMDS</a>) (Berkeley)</li>
            </ul>
            <br>
        </div>
      </section>


    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

  </body>

</html>
